# Phishing Detection using Transformer Models

## Project Description
Developed an advanced phishing detection system using state-of-the-art transformer models (DistilBERT and RoBERTa) to classify text messages as phishing or legitimate, achieving 98-100% accuracy with comprehensive text preprocessing and model comparison analysis.

## üöÄ Overview
This project implements a robust phishing detection system that uses natural language processing and transformer-based models to identify malicious phishing attempts in text messages. The system includes advanced text preprocessing, model training, evaluation, and comparative analysis between different transformer architectures.

## üéØ Key Features
- **Advanced Text Preprocessing**: Comprehensive cleaning including URL removal, mention filtering, and normalization
- **Transformer Models**: Implementation of DistilBERT and RoBERTa for binary classification
- **High Accuracy**: Achieved 98% accuracy with DistilBERT and 100% with RoBERTa
- **Robust Data Handling**: Automatic dataset cleaning and validation
- **Visual Analysis**: Confusion matrix and model comparison visualizations
- **Production Ready**: Complete pipeline from data upload to model evaluation

## üèóÔ∏è Technical Architecture
- **Framework**: Hugging Face Transformers with PyTorch backend
- **Models**: 
  - DistilBERT-base-uncased (98% accuracy)
  - RoBERTa-base (100% accuracy)
- **Task**: Binary sequence classification (Phishing vs Legitimate)
- **Preprocessing**: Custom text cleaning with regex patterns
- **Evaluation**: Classification reports, confusion matrices, accuracy comparison

## üìÅ Project Structure
```
phishing-detection/
‚îú‚îÄ‚îÄ phishing_detection.py       # Main training and evaluation script
‚îú‚îÄ‚îÄ dataset/                    # CSV dataset files (not included - see Dataset section)
‚îú‚îÄ‚îÄ results/                    # Model training outputs
‚îú‚îÄ‚îÄ logs/                       # Training logs and metrics
‚îú‚îÄ‚îÄ visualizations/             # Generated plots and charts
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png    # Model performance visualization
‚îÇ   ‚îî‚îÄ‚îÄ accuracy_comparison.png # DistilBERT vs RoBERTa comparison
‚îú‚îÄ‚îÄ requirements.txt            # Dependencies
‚îî‚îÄ‚îÄ README.md                   # This file
```

## üîß Requirements
```
pandas>=1.5.0
transformers>=4.25.0
datasets>=2.8.0
torch>=1.13.0
scikit-learn>=1.2.0
matplotlib>=3.6.0
seaborn>=0.12.0
google-colab (if running on Colab)
```

## üìä Dataset Requirements
The model expects a CSV file with the following structure:
- **text_combined**: Column containing the text messages to classify
- **label**: Binary labels (0 = Legitimate, 1 = Phishing)

### Dataset Preprocessing Features
- **URL Removal**: Strips http/https links and www references
- **Social Media Cleaning**: Removes @mentions and #hashtags
- **Text Normalization**: Removes special characters and converts to lowercase
- **Data Validation**: Filters invalid labels and handles missing values
- **Format Conversion**: Transforms data for transformer model compatibility

## üöÄ Usage

### Running in Google Colab (Recommended)
```python
# Upload your CSV dataset when prompted
# The script will automatically handle file upload dialog

# Run the complete pipeline
%run phishing_detection.py
```

### Local Execution
```python
# Install dependencies
pip install -r requirements.txt

# Modify the file upload section to load your CSV:
# Replace the files.upload() section with:
df = pd.read_csv('your_dataset.csv', low_memory=False)

# Run the script
python phishing_detection.py
```

## üß† Model Architecture & Training

### DistilBERT Configuration
```python
model = AutoModelForSequenceClassification.from_pretrained(
    "distilbert-base-uncased", 
    num_labels=2
)
```

### Training Parameters
- **Batch Size**: 8 (train/eval)
- **Epochs**: 3
- **Learning Rate**: 2e-5
- **Optimizer**: AdamW (default)
- **Evaluation Strategy**: Per epoch
- **Max Sequence Length**: 512 tokens (with padding/truncation)

### Text Preprocessing Pipeline
1. **URL Sanitization**: Removes all web links
2. **Social Media Filtering**: Strips mentions and hashtags
3. **Character Normalization**: Keeps only alphanumeric characters
4. **Case Normalization**: Converts to lowercase
5. **Tokenization**: DistilBERT tokenizer with padding/truncation

## üìà Model Performance

### Results Summary
| Model | Accuracy | Performance |
|-------|----------|-------------|
| DistilBERT | 98% | High efficiency, fast inference |
| RoBERTa | 100% | Maximum accuracy, robust detection |

### Key Metrics
- **Precision**: High precision in phishing detection
- **Recall**: Excellent recall for legitimate messages
- **F1-Score**: Balanced performance across both classes
- **Confusion Matrix**: Visual performance analysis included

## üé® Visualizations
The project generates comprehensive visualizations:
- **Confusion Matrix**: Heatmap showing prediction accuracy
- **Model Comparison**: Bar chart comparing DistilBERT vs RoBERTa
- **Performance Metrics**: Detailed classification reports

## üî¨ Technical Implementation Details

### Data Cleaning Function
```python
def clean_text(text):
    # Remove URLs
    text = re.sub(r"http\S+|www\S+|https\S+", '', text, flags=re.MULTILINE)
    # Remove mentions and hashtags
    text = re.sub(r'@\w+|#\w+', '', text)
    # Keep only alphanumeric characters
    text = re.sub(r'[^A-Za-z0-9 ]+', '', text)
    return text.lower()
```

### Dataset Validation
- Automatic removal of null values
- Label validation (only 0/1 accepted)
- Type conversion for model compatibility
- Train/test split (80/20)

## üìã Installation & Setup

### Option 1: Google Colab (Recommended)
```python
# Clone repository
!git clone https://github.com/yourusername/phishing-detection.git
%cd phishing-detection

# Install dependencies (most pre-installed in Colab)
!pip install datasets transformers

# Upload your CSV dataset when prompted
# Run the script
%run phishing_detection.py
```

### Option 2: Local Setup
```bash
# Clone repository
git clone https://github.com/yourusername/phishing-detection.git
cd phishing-detection

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Prepare your dataset
# Place your CSV file in the project directory
# Modify the script to load your specific file

# Run the script
python phishing_detection.py
```

## üéØ Use Cases & Applications
- **Email Security**: Automated phishing email detection
- **SMS Filtering**: Mobile message security systems
- **Social Media**: Detecting malicious messages on platforms
- **Enterprise Security**: Corporate communication protection
- **Research**: Cybersecurity and NLP research applications

## üîÆ Future Enhancements
- [ ] Multi-language phishing detection
- [ ] Real-time detection API
- [ ] Advanced feature engineering
- [ ] Ensemble model combinations
- [ ] Adversarial robustness testing
- [ ] Mobile app integration
- [ ] Custom domain-specific fine-tuning

## üìä Dataset Information
Due to privacy and size constraints, the dataset is not included in this repository. 

**Expected CSV Format:**
```csv
text_combined,label
"Congratulations! You've won $1000. Click here to claim...",1
"Meeting scheduled for tomorrow at 3 PM",0
```

**Dataset Guidelines:**
- Ensure balanced classes for optimal training
- Include diverse phishing and legitimate examples
- Minimum 1000+ samples recommended for good performance
- Clean data improves model accuracy significantly

## ü§ù Contributing
Contributions are welcome! Areas for contribution:
- Additional transformer model implementations
- Enhanced preprocessing techniques
- Performance optimization
- Multi-language support
- Real-time detection features

## üìÑ License
This project is licensed under the MIT License - see the LICENSE file for details.

## üîí Ethical Considerations
This tool is designed for:
- ‚úÖ Legitimate cybersecurity research
- ‚úÖ Educational purposes
- ‚úÖ Protecting users from phishing attacks
- ‚ùå Not for creating or distributing phishing content

## üìö References & Acknowledgments
- **Hugging Face Transformers**: For the amazing transformer models and library
- **DistilBERT**: "DistilBERT, a distilled version of BERT" (Sanh et al.)
- **RoBERTa**: "RoBERTa: A Robustly Optimized BERT Pretraining Approach" (Liu et al.)
- **Scikit-learn**: For evaluation metrics and utilities

## üë§ Contact
Feel free to reach out for questions, collaborations, or discussions about NLP, cybersecurity, and transformer models!

---

**‚≠ê If you find this project useful for cybersecurity research or education, please give it a star!**

*This project demonstrates advanced skills in NLP, transformer models, cybersecurity, and production-ready ML pipeline development.*
