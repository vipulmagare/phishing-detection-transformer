# -*- coding: utf-8 -*-
"""Project_FinalDraft.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c7UcvavGKXXpqFbnZw0O-wJAe8-ctpBs
"""

import pandas as pd
from google.colab import files
from datasets import Dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import torch
import re

'''
here i'm opening a file upload dialog in Colab and it will also the selected CSV file into a pandas DataFrame

'''
uploaded = files.upload()
df = pd.read_csv(next(iter(uploaded)), low_memory=False)

'''
here i'm defining a function to clean the text column and that will Removes URLs, @mentions and hashtags
special characters and punctuation and Converts everything to lowercase

'''
def clean_text(text):
    text = re.sub(r"http\S+|www\S+|https\S+", '', text, flags=re.MULTILINE)
    text = re.sub(r'@\w+|#\w+', '', text)
    text = re.sub(r'[^A-Za-z0-9 ]+', '', text)
    return text.lower()

'''
this is extra step to clean my dataset as i got different data in my label column
along with 0 & 1 that cuased me error while training the model.

i'm Making a copy of the relevant columns and Keeping only rows where the label is '0' or '1'
also Converting the label column to integers from string so the model can use it.
and applying the custom text cleaning function to each message in the dataset.

'''
df_clean = df[['text_combined', 'label']].copy()
df_clean.dropna(subset=['text_combined', 'label'], inplace=True)
df_clean = df_clean[df_clean['label'].astype(str).isin(['0', '1'])]
df_clean['label'] = df_clean['label'].astype(int)
df_clean['text_combined'] = df_clean['text_combined'].apply(clean_text)

'''
here i'm loading the tokenizer to convert raw text into tokens that the model can understand.
also converting the cleaned pandas DataFrame into a Hugging Face Dataset format
to makes it easier to process with built-in transformers tools.

'''
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
hf_dataset = Dataset.from_pandas(df_clean)

'''
 here i'm defining a function that applies the tokenizer to the text data.
 It also adds padding to make all input the same length and truncates long texts.
 and applying the tokenizer to the entire dataset with removing columns i no longer need.
 i'm also converting the dataset format to PyTorch tensors so the model can use it.

'''

def tokenize_function(example):
    return tokenizer(example["text_combined"], padding="max_length", truncation=True)

tokenized_dataset = hf_dataset.map(tokenize_function, batched=True)
tokenized_dataset = tokenized_dataset.remove_columns(["text_combined", "__index_level_0__"])
tokenized_dataset.set_format("torch")

'''
i'm Spliting the tokenized dataset into training (80%) and testing (20%) sets.
Also loading the pre-trained DistilBERT model for binary classification.
'''
train_test = tokenized_dataset.train_test_split(test_size=0.2)
train_dataset = train_test["train"]
test_dataset = train_test["test"]
model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=2)

'''
here i'm defining training settings like batch size, number of epochs, learning rate ND more.
and setting up the Hugging Face Trainer object that will handles training and evaluation for me.

'''
training_args = TrainingArguments(
    output_dir="./results",
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    learning_rate=2e-5,
    logging_dir='./logs',
    evaluation_strategy="epoch",
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
)

# this will start training process
trainer.train()

'''
i'm using trained model to make predictions on the test set and
extracting true labels and predicted labels.

'''
predictions = trainer.predict(test_dataset)
y_true = predictions.label_ids
y_pred = torch.argmax(torch.tensor(predictions.predictions), axis=1).numpy()
print(classification_report(y_true, y_pred))

'''
here i'm creatig a confusion matrix to visualize how well the model performed.
'''
cm = confusion_matrix(y_true, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=["Not Phishing", "Phishing"],
            yticklabels=["Not Phishing", "Phishing"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

'''
i'm creating a bar chart to compare the accuracy of the distilbert and RoBERTa models.
'''

import matplotlib.pyplot as plt
distilbert_accuracy = 0.98
roberta_accuracy = 1.00
models = ['distilbert', 'RoBERTa']
accuracies = [distilbert_accuracy, roberta_accuracy]
plt.bar(models, accuracies)
plt.ylim(0, 1)
plt.ylabel('Accuracy')
plt.title('Model Accuracy Comparison: distilbert vs RoBERTa')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

